# app/ingest_simble.py

from pathlib import Path

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain_community.vectorstores import FAISS

from app.config import get_embeddings  # –±–µ—Ä—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ config.py


# === –ü—É—Ç–∏ ===

# –ë–∞–∑–æ–≤–∞—è –ø–∞–ø–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞
BASE_DIR = Path(__file__).resolve().parent.parent

# –ì–¥–µ –ª–µ–∂–∞—Ç —Å—ã—Ä—ã–µ txt-—Ñ–∞–π–ª—ã Simble
DATA_RAW_DIR = BASE_DIR / "data" / "raw"

# –ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã (ASCII-–ø—É—Ç—å, –±–µ–∑ –∫–æ—Ä–µ–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤!)
VECTORES_DIR = Path.home() / "faiss_vecstores"
SIMBLE_PART1_DIR = VECTORES_DIR / "simble_part1"
SIMBLE_PART2_DIR = VECTORES_DIR / "simble_part2"


def load_text(path: Path) -> str:
    """–ß–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –≤ UTF-8."""
    if not path.exists():
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
    return path.read_text(encoding="utf-8")


def make_docs(text: str, source_name: str) -> list[Document]:
    """–û–±–æ—Ä–∞—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –≤ Document, –∑–∞—Ç–µ–º –ø–æ—Ä–µ–∂–µ–º –Ω–∞ —á–∞–Ω–∫–∏."""
    doc = Document(page_content=text, metadata={"source": source_name})
    return [doc]


def split_into_chunks(docs: list[Document]) -> list[Document]:
    """–†–µ–∂–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ —á–∞–Ω–∫–∏."""
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", ". ", " ", ""],
    )
    return splitter.split_documents(docs)


def build_faiss_for_file(input_path: Path, output_dir: Path) -> None:
    """–°—Ç—Ä–æ–∏–º FAISS-–≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ."""
    print(f"\n=== –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {input_path.name} ===")
    text = load_text(input_path)
    docs = make_docs(text, source_name=input_path.name)
    chunks = split_into_chunks(docs)
    print(f"üëâ –ü–æ–ª—É—á–∏–ª–æ—Å—å —á–∞–Ω–∫–æ–≤: {len(chunks)}")

    embeddings = get_embeddings()

    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –ø–∞–ø–∫–∞ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    output_dir.mkdir(parents=True, exist_ok=True)

    vecstore = FAISS.from_documents(chunks, embeddings)
    vecstore.save_local(str(output_dir))

    print(f"‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {output_dir}")


def main() -> None:
    base1_path = DATA_RAW_DIR / "simble_base1.txt"
    base2_path = DATA_RAW_DIR / "simble_base2.txt"

    print(f"DATA_RAW_DIR = {DATA_RAW_DIR}")
    print(f"SIMBLE_PART1_DIR = {SIMBLE_PART1_DIR}")
    print(f"SIMBLE_PART2_DIR = {SIMBLE_PART2_DIR}")

    build_faiss_for_file(base1_path, SIMBLE_PART1_DIR)
    build_faiss_for_file(base2_path, SIMBLE_PART2_DIR)

    print("\nüéâ –ì–æ—Ç–æ–≤–æ: –¥–≤–µ –æ—Ç–¥–µ–ª—å–Ω—ã–µ FAISS-–±–∞–∑—ã —Å–æ–∑–¥–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")


if __name__ == "__main__":
    main()
